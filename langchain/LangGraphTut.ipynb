{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5cdac38-a0b7-4e84-ba48-767a30e00467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, MessagesState\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e230726e-00db-4987-a9ae-388b1632e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langGraph MapReduce imports\n",
    "import operator\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3b0775-bf62-4073-9773-076e17262cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "load_dotenv() ## ensure that your .env file in the same directory as this notebook has the OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f2102b-b407-4b50-b147-f6c3b861582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53df7b08-0844-4261-8a38-3431761df97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.prebuilt import ToolInvocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b0fb52-3264-4e53-ab56-a04a31b263b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup tool to anomalous traces with their descriptions and connections to initial prompt\n",
    "@tool\n",
    "def load_anomolous_traces_v1(query: str): # query may not be necessary, or could be the identifier\n",
    "    \"\"\"Inject the anomalous traces and the description of anomaly for hypothesis generation\"\"\"\n",
    "    # In the real implementation, this will not be called at all and will instead\n",
    "    # be handled via mapreduce faculty over all traces with the explorer multimodal LLM.\n",
    "    return [\n",
    "        f\"I have evaluated potential anomalies with {query}. Result: the program appears to be stalling when calling the user identity service, as indicated in the figure provided as part of the query.\"\n",
    "    ]\n",
    "\n",
    "tools = [load_anomolous_traces_v1]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa142212-a752-4641-8840-d262425ffd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [Optionally] if we were using a human feedback mechanism, this is what we would use\n",
    "class RequestAnomalyInejection(BaseModel):\n",
    "    question: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722dad3e-f512-4e55-b06e-32726b56187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now let's bind our tool to the chatbot\n",
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c85b135-8c0a-4547-be59-5f5874ffdba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState) -> Literal[\"continue\", \"end\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # [Optionally] If tool call is asking Human, we return that node\n",
    "    # You could also add logic here to let some system know that there's something that requires Human input\n",
    "    # For example, send a slack message, etc\n",
    "    # elif last_message.tool_calls[0][\"name\"] == \"AskHuman\":\n",
    "    #     return \"ask_human\"\n",
    "    # # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "        # return \"tools\"\n",
    "\n",
    "# Optionally, we define a fake node for prompting human\n",
    "# def ask_human(state):\n",
    "#     pass\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c627a0f4-0643-48d6-a64e-7ec4c29f44f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build graph\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"explorer\", tool_node)\n",
    "# workflow.add_node(\"hypothesizer\", )\n",
    "# [Optionally] workflow.add_node(\"ask_human\", ask_human)\n",
    "\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"explorer\",\n",
    "        # We may ask the human [Optionally]\n",
    "        # \"ask_human\": \"ask_human\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"explorer\", \"agent\")\n",
    "\n",
    "# optionally After we get back the human response, we go back to the agent\n",
    "# workflow.add_edge(\"ask_human\", \"agent\")\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "# We add a breakpoint BEFORE the `ask_human` node so it never executes\n",
    "# app = workflow.compile(checkpointer=memory, interrupt_before=[\"ask_human\"])\n",
    "\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a901f9b-d049-4cce-8bbe-eb8f146c2609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Use the load_anomalous_traces tool to find anomalies, then tell me what's going on with our program.\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************OWK9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m      4\u001b[0m input_message \u001b[38;5;241m=\u001b[39m HumanMessage(\n\u001b[1;32m      5\u001b[0m     content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse the load_anomalous_traces tool to find anomalies, then tell me what\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms going on with our program.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_message\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1073\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m-> 1073\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1639\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1638\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1639\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1644\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langgraph/pregel/retry.py:72\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     70\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2505\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2501\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2502\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2503\u001b[0m )\n\u001b[1;32m   2504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2505\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2507\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langgraph/utils.py:95\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m     94\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 95\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m, in \u001b[0;36mcall_model\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_model\u001b[39m(state: MessagesState):\n\u001b[1;32m     23\u001b[0m     messages \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# We return a list, because this will get added to the existing list\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]}\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:4588\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4584\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4585\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4586\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4587\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4589\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4590\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4592\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:248\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    244\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    245\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    247\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 248\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    258\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:677\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    671\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    675\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    676\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:534\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    533\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 534\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    535\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    536\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    538\u001b[0m ]\n\u001b[1;32m    539\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:524\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 524\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m         )\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:749\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 749\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:549\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    548\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 549\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/openai/resources/chat/completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/openai/_base_client.py:1250\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1238\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1246\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1247\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1248\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1249\u001b[0m     )\n\u001b[0;32m-> 1250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/openai/_base_client.py:931\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    924\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    929\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    930\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/openai/_base_client.py:1030\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1029\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1033\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1034\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1038\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************OWK9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(\n",
    "    content=\"Use the load_anomalous_traces tool to find anomalies, then tell me what's going on with our program.\"\n",
    ")\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73967302-b255-4d4f-893d-d1adfb91b398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
