{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict, Union, Optional, Tuple, Literal\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import functools\n",
    "\n",
    "### Agents\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent, create_tool_calling_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain import hub\n",
    "##\n",
    "\n",
    "### Tools\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "# Utils\n",
    "from pathlib import Path\n",
    "###\n",
    "\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState\n",
    "from langgraph.prebuilt import create_react_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "load_dotenv(os.path.join(parent_dir, '.env'))\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "load_dotenv() ## ensure that your .env file in the same directory as this notebook has the OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool utils\n",
    "\n",
    "WORKING_DIRECTORY = Path('./playground/multi_trace/dsph_fL1/')\n",
    "\n",
    "# tavily_tool = TavilySearchResults(max_results=5) # TODO: get TavilyAPIKey\n",
    "python_repl_tool = PythonREPLTool()\n",
    "\n",
    "@tool\n",
    "def scrape_webpages(urls: List[str]) -> str:\n",
    "    \"\"\"Use requests and bs4 to scrape the provided web pages for detailed information.\"\"\"\n",
    "    loader = WebBaseLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'\\n{doc.page_content}\\n'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "@tool # DEP:\n",
    "def get_telemetry(queries: List[str]) -> str: \n",
    "    \"\"\"Use Alessandro's API to request samples of traces and/or metrics (gauges or counters) from prometheus and jaeger.\n",
    "    @TODO: refine type signature for input to be a tuple of counted calls\n",
    "    @TODO: implement the actual functionality\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "## -- File System Interaction Toolkit\n",
    "\n",
    "# This will be run before the anomaly enumeration agents\n",
    "# It makes it so they are more aware of the current state\n",
    "# of the working directory.\n",
    "def prelude(state):\n",
    "    written_files = []\n",
    "    if not WORKING_DIRECTORY.exists():\n",
    "        WORKING_DIRECTORY.mkdir()\n",
    "    try:\n",
    "        written_files = [\n",
    "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
    "        ]\n",
    "    except Exception:\n",
    "        pass\n",
    "    if not written_files:\n",
    "        return {**state, \"current_files\": \"No files written.\"}\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_files\": \"\\nBelow are the files that exist in metrics filesystem DB:\\n\"\n",
    "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is not None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])\n",
    "\n",
    "tools = [python_repl_tool, read_document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm.bind_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor_prompt = \"\"\"You are an expert agent responsible for executing steps in a plan for anomaly detection in microservice applications. Your task is to carry out the current step and evaluate its outcome. \n",
    "{current_files}\n",
    "\"\"\"\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    return executor\n",
    "# Choose the LLM that will drive the agent\n",
    "agent_executor = prelude | create_agent(llm, tools, executor_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow in future\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def create_objective(slo_violation: str) -> str: \n",
    "    return f\"\"\"\n",
    "Objective: Detect anomalies in microservice application traces and metrics based on an SLO violation.\n",
    "\n",
    "Context:\n",
    "- You have access to a working directory containing:\n",
    "  1. main_traces.csv: A summary of Jaeger traces for all calls in the workload, including headers for traceID, duration-ms, startTime, endTime, rpcErrors, operation, and services_involved.\n",
    "  2. Individual trace tree JSON files, each named after its respective traceID.\n",
    "- Anomalies may include errors, extreme bottlenecks, recursions, or other unusual patterns.\n",
    "- The plan will be executed by an agent, not by you.\n",
    "\n",
    "Specific SLO Violation: {slo_violation}\n",
    "\n",
    "Required Output: Either a list of anomalous trace IDs with brief explanations of why they were flagged, or FALSE if no anomalies were found.\n",
    "\n",
    "Additional Instructions:\n",
    "- Do not execute any steps or perform any analysis yourself.\n",
    "- Describe actions the execution agent should take at each step.\n",
    "- Include steps for loading data, performing statistical analysis, identifying potential anomalies, and summarizing findings.\n",
    "- Keep in mind that the executor agent will have access to the directory and appropriate files.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: determine if the fused vs separated prompt are better\n",
    "planner_prompt_text_expanded = \"\"\"\n",
    "You are an expert planner specializing in anomaly detection for microservice applications. Your task is to create a detailed step-by-step plan to investigate potential anomalies in telemetry data. This plan will be used by an execution agent, so you should not execute any steps yourself.\n",
    "\n",
    "You will be planning based on the following scenario:\n",
    "\n",
    "An SLO violation has occurred, and you have access to a working directory containing:\n",
    "\n",
    "1. main_traces.csv: A summary of Jaeger traces for all calls in the workload, including headers for traceID, duration-ms, startTime, endTime, rpcErrors, operation, and services_involved.\n",
    "2. Individual trace tree JSON files, each named after its respective traceID.\n",
    "\n",
    "The objective is to analyze this data, identify any anomalies, and provide a summary of findings. Anomalies may include errors, extreme bottlenecks, recursions, or other unusual patterns.\n",
    "\n",
    "Create a detailed plan to accomplish this task. Each step should be clear, concise, and contain all necessary information. The final step should describe how to present the results: either a list of anomalous trace IDs with a brief explanation of why they were flagged, or FALSE if no anomalies were found.\n",
    "\n",
    "Your plan should include steps for:\n",
    "- Loading and inspecting the data\n",
    "- Analyzing trace durations, errors, and service interactions\n",
    "- Identifying potential anomalies\n",
    "- Investigating suspicious patterns in individual trace JSON files\n",
    "- Compiling and summarizing findings\n",
    "\n",
    "Remember, this is a planning task. Do not include steps for executing code or performing the analysis yourself. Instead, describe what actions the execution agent should take at each step.\n",
    "\n",
    "Here's an example of how your plan might start:\n",
    "\n",
    "1. Load the main_traces.csv file into a data analysis tool or framework.\n",
    "2. Calculate basic statistics for the 'duration-ms' column (mean, median, standard deviation).\n",
    "3. Identify traces with durations exceeding 2 standard deviations from the mean.\n",
    "4. Create a list of all unique 'services_involved' and their frequency of occurrence.\n",
    "5. Identify traces with 'rpcErrors' greater than zero.\n",
    "6. For each potential anomaly identified in steps 3 and 5, locate the corresponding JSON file using the traceID.\n",
    "7. ...\n",
    "\n",
    "Continue the plan to cover all necessary steps for thorough anomaly detection and result reporting. The final step should describe how to present the findings.\n",
    "\"\"\"\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "planner = planner_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o\", temperature=0\n",
    ").with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the follow steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "replanner = replanner_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o\", temperature=0\n",
    ").with_structured_output(Act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    agent_response = await agent_executor.ainvoke(\n",
    "        {\"messages\": [(\"user\", task_formatted)]}\n",
    "    )\n",
    "    return {\n",
    "        \"past_steps\": (task, agent_response[\"messages\"][-1]),\n",
    "        # \"past_steps\": (task, agent_response[\"messages\"][-1].content),\n",
    "    }\n",
    "\n",
    "\n",
    "async def plan_step(state: PlanExecute):\n",
    "    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    return {\"plan\": plan.steps}\n",
    "\n",
    "\n",
    "async def replan_step(state: PlanExecute):\n",
    "    output = await replanner.ainvoke(state)\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    else:\n",
    "        return {\"plan\": output.action.steps}\n",
    "\n",
    "\n",
    "def should_end(state: PlanExecute) -> Literal[\"agent\", \"__end__\"]:\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"__end__\"\n",
    "    else:\n",
    "        return \"agent\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# Add the plan node\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "\n",
    "# Add the execution step\n",
    "workflow.add_node(\"agent\", execute_step)\n",
    "\n",
    "# Add a replan node\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "# From plan we go to agent\n",
    "workflow.add_edge(\"planner\", \"agent\")\n",
    "\n",
    "# From agent, we replan\n",
    "workflow.add_edge(\"agent\", \"replan\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_end,\n",
    ")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan': ['Load the main_traces.csv file into a DataFrame.', 'Filter the DataFrame to include only traces with duration-ms greater than 2000 milliseconds.', 'Calculate the percentage of traces that exceed the 2000 milliseconds threshold.', 'If the percentage of traces exceeding the threshold is less than or equal to 20%, return FALSE and stop further analysis.', 'For each trace that exceeds the 2000 milliseconds threshold, load the corresponding JSON trace tree file using the traceID.', 'Analyze each JSON trace tree file for anomalies such as rpcErrors, extreme bottlenecks, recursions, or other unusual patterns.', 'Compile a list of trace IDs that exhibit anomalies along with brief explanations for each anomaly.', 'Return the list of anomalous trace IDs with explanations.']}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `read_document` with `{'file_name': 'f1/unknown_service:frontend_service_process.csv'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mec5866bd3cfa717a5f3dd31347fe6a89,5532.43,1721571409600370,1721571415132800,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "2b3bc1603f7a1f5f690e5151a7546cfb,5513.591,1721571413607947,1721571419121538,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "7c0a47e09a740513829e2d1d9c8785b4,5515.385,1721571410602370,1721571416117755,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "07ebbe0dab2565ca19e8195c9894073c,5514.105,1721571416612001,1721571422126106,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "a28592155f048496d4d2c9f9d4a9b1ed,5513.458,1721571415610473,1721571421123931,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "331045542c35adbecef9bcb3ed316625,5513.787,1721571414609113,1721571420122900,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "1545830e55e915022a9baf9a0b7bba43,5514.629,1721571417613998,1721571423128627,False,SearchHandler start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "0fade9b7a1adf0a59afd909304e302c2,5513.852,1721571411604788,1721571417118640,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "0dc4b8d9fcaff8760271197a5a5f5d6b,5530.093,1721571412606510,1721571418136603,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "f26e915335df4170b4e55b544bdebba6,5520.775,1721571418620187,1721571424140962,False,Nearby start,unknown_service:frontend_service_process;unknown_service:search_service_process;unknown_service:geo_service_process\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `import pandas as pd\n",
      "from io import StringIO\n",
      "\n",
      "# CSV data\n",
      "csv_data = '''traceID,duration-ms,start-time,end-time,rpcStatus,spanName,services\n",
      "\n",
      "\n",
      "ec5866bd3cfa717a5f3dd31347fe6a89,5532.43,1721571409600370,1721571415132800,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "2b3bc1603f7a1f5f690e5151a7546cfb,5513.591,1721571413607947,1721571419121538,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "7c0a47e09a740513829e2d1d9c8785b4,5515.385,1721571410602370,1721571416117755,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "07ebbe0dab2565ca19e8195c9894073c,5514.105,1721571416612001,1721571422126106,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "a28592155f048496d4d2c9f9d4a9b1ed,5513.458,1721571415610473,1721571421123931,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "331045542c35adbecef9bcb3ed316625,5513.787,1721571414609113,1721571420122900,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "1545830e55e915022a9baf9a0b7bba43,5514.629,1721571417613998,1721571423128627,False,SearchHandler start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "0fade9b7a1adf0a59afd909304e302c2,5513.852,1721571411604788,1721571417118640,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "0dc4b8d9fcaff8760271197a5a5f5d6b,5530.093,1721571412606510,1721571418136603,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "\n",
      "f26e915335df4170b4e55b544bdebba6,5520.775,1721571418620187,1721571424140962,False,Nearby start,unknown_service:frontend_service_process;unknown_service:search_service_process;unknown_service:geo_service_process'''\n",
      "\n",
      "# Creating DataFrame\n",
      "df = pd.read_csv(StringIO(csv_data))\n",
      "print(df.head())`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mModuleNotFoundError(\"No module named 'pandas'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `import csv\n",
      "from io import StringIO\n",
      "\n",
      "# CSV data\n",
      "csv_data = '''traceID,duration-ms,start-time,end-time,rpcStatus,spanName,services\n",
      "ec5866bd3cfa717a5f3dd31347fe6a89,5532.43,1721571409600370,1721571415132800,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "2b3bc1603f7a1f5f690e5151a7546cfb,5513.591,1721571413607947,1721571419121538,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "7c0a47e09a740513829e2d1d9c8785b4,5515.385,1721571410602370,1721571416117755,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "07ebbe0dab2565ca19e8195c9894073c,5514.105,1721571416612001,1721571422126106,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "a28592155f048496d4d2c9f9d4a9b1ed,5513.458,1721571415610473,1721571421123931,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "331045542c35adbecef9bcb3ed316625,5513.787,1721571414609113,1721571420122900,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "1545830e55e915022a9baf9a0b7bba43,5514.629,1721571417613998,1721571423128627,False,SearchHandler start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "0fade9b7a1adf0a59afd909304e302c2,5513.852,1721571411604788,1721571417118640,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "0dc4b8d9fcaff8760271197a5a5f5d6b,5530.093,1721571412606510,1721571418136603,False,Nearby start,unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process\n",
      "f26e915335df4170b4e55b544bdebba6,5520.775,1721571418620187,1721571424140962,False,Nearby start,unknown_service:frontend_service_process;unknown_service:search_service_process;unknown_service:geo_service_process'''\n",
      "\n",
      "# Read the CSV data into a list of dictionaries\n",
      "csv_file = StringIO(csv_data)\n",
      "reader = csv.DictReader(csv_file)\n",
      "rows = list(reader)\n",
      "\n",
      "# Display the data\n",
      "df = rows\n",
      "print(df)`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'traceID': 'ec5866bd3cfa717a5f3dd31347fe6a89', 'duration-ms': '5532.43', 'start-time': '1721571409600370', 'end-time': '1721571415132800', 'rpcStatus': 'False', 'spanName': 'Nearby start', 'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'}, {'traceID': '2b3bc1603f7a1f5f690e5151a7546cfb', 'duration-ms': '5513.591', 'start-time': '1721571413607947', 'end-time': '1721571419121538', 'rpcStatus': 'False', 'spanName': 'Nearby start', 'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'}, {'traceID': '7c0a47e09a740513829e2d1d9c8785b4', 'duration-ms': '5515.385', 'start-time': '1721571410602370', 'end-time': '1721571416117755', 'rpcStatus': 'False', 'spanName': 'Nearby start', 'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'}, {'traceID': '07ebbe0dab2565ca19e8195c9894073c', 'duration-ms': '5514.105', 'start-time': '1721571416612001', 'end-time': '1721571422126106', 'rpcStatus': 'False', 'spanName': 'Nearby start', 'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'}, {'traceID': 'a28592155f048496d4d2c9f9d4a9b1ed', 'duration-ms': '5513.458', 'start-time': '1721571415610473', 'end-time': '1721571421123931', 'rpcStatus': 'False', 'spanName': 'Nearby start', 'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'}, {'traceID': '331045542c35adbecef9bcb3ed316625', 'duration-ms': '5513.787', 'start-time': '1721571414609113', 'end-time': '1721571420122900', 'rpcStatus': 'False', 'spanName': 'Nearby start', 'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'}, {'traceID': '1545830e55e915022a9baf9a0b7bba43', 'duration-ms': '5514.629', 'start-time': '1721571417613998', 'end-time': '1721571423128627', 'rpcStatus': 'False', 'spanName': 'SearchHandler start', 'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'}, {'traceID': '0fade9b7a1adf0a59afd909304e302c2', 'duration-ms': '5513.852', 'start-time': '1721571411604788', 'end-time': '1721571417118640', 'rpcStatus': 'False', 'spanName': 'Nearby start', 'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'}, {'traceID': '0dc4b8d9fcaff8760271197a5a5f5d6b', 'duration-ms': '5530.093', 'start-time': '1721571412606510', 'end-time': '1721571418136603', 'rpcStatus': 'False', 'spanName': 'Nearby start', 'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'}, {'traceID': 'f26e915335df4170b4e55b544bdebba6', 'duration-ms': '5520.775', 'start-time': '1721571418620187', 'end-time': '1721571424140962', 'rpcStatus': 'False', 'spanName': 'Nearby start', 'services': 'unknown_service:frontend_service_process;unknown_service:search_service_process;unknown_service:geo_service_process'}]\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThe main traces CSV file has been successfully loaded into a DataFrame-like structure (a list of dictionaries in this case). Here is the loaded data:\n",
      "\n",
      "```plaintext\n",
      "[\n",
      "    {\n",
      "        'traceID': 'ec5866bd3cfa717a5f3dd31347fe6a89',\n",
      "        'duration-ms': '5532.43',\n",
      "        'start-time': '1721571409600370',\n",
      "        'end-time': '1721571415132800',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'Nearby start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'\n",
      "    },\n",
      "    {\n",
      "        'traceID': '2b3bc1603f7a1f5f690e5151a7546cfb',\n",
      "        'duration-ms': '5513.591',\n",
      "        'start-time': '1721571413607947',\n",
      "        'end-time': '1721571419121538',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'Nearby start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'\n",
      "    },\n",
      "    {\n",
      "        'traceID': '7c0a47e09a740513829e2d1d9c8785b4',\n",
      "        'duration-ms': '5515.385',\n",
      "        'start-time': '1721571410602370',\n",
      "        'end-time': '1721571416117755',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'Nearby start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'\n",
      "    },\n",
      "    {\n",
      "        'traceID': '07ebbe0dab2565ca19e8195c9894073c',\n",
      "        'duration-ms': '5514.105',\n",
      "        'start-time': '1721571416612001',\n",
      "        'end-time': '1721571422126106',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'Nearby start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'\n",
      "    },\n",
      "    {\n",
      "        'traceID': 'a28592155f048496d4d2c9f9d4a9b1ed',\n",
      "        'duration-ms': '5513.458',\n",
      "        'start-time': '1721571415610473',\n",
      "        'end-time': '1721571421123931',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'Nearby start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'\n",
      "    },\n",
      "    {\n",
      "        'traceID': '331045542c35adbecef9bcb3ed316625',\n",
      "        'duration-ms': '5513.787',\n",
      "        'start-time': '1721571414609113',\n",
      "        'end-time': '1721571420122900',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'Nearby start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'\n",
      "    },\n",
      "    {\n",
      "        'traceID': '1545830e55e915022a9baf9a0b7bba43',\n",
      "        'duration-ms': '5514.629',\n",
      "        'start-time': '1721571417613998',\n",
      "        'end-time': '1721571423128627',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'SearchHandler start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'\n",
      "    },\n",
      "    {\n",
      "        'traceID': '0fade9b7a1adf0a59afd909304e302c2',\n",
      "        'duration-ms': '5513.852',\n",
      "        'start-time': '1721571411604788',\n",
      "        'end-time': '1721571417118640',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'Nearby start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'\n",
      "    },\n",
      "    {\n",
      "        'traceID': '0dc4b8d9fcaff8760271197a5a5f5d6b',\n",
      "        'duration-ms': '5530.093',\n",
      "        'start-time': '1721571412606510',\n",
      "        'end-time': '1721571418136603',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'Nearby start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:wlgen_proc;unknown_service:search_service_process'\n",
      "    },\n",
      "    {\n",
      "        'traceID': 'f26e915335df4170b4e55b544bdebba6',\n",
      "        'duration-ms': '5520.775',\n",
      "        'start-time': '1721571418620187',\n",
      "        'end-time': '1721571424140962',\n",
      "        'rpcStatus': 'False',\n",
      "        'spanName': 'Nearby start',\n",
      "        'services': 'unknown_service:frontend_service_process;unknown_service:search_service_process;unknown_service:geo_service_process'\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "The next step is to filter this data to include only traces with `duration-ms` greater than 2000 milliseconds. Should I proceed with this?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m}\n\u001b[1;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: create_objective(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe have observed an increase in service latency above 2 seconds for more than 20\u001b[39m\u001b[38;5;132;01m% o\u001b[39;00m\u001b[38;5;124mf user requests, violating service level agreements.\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mastream(inputs, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__end__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1431\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m-> 1431\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1639\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1638\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1639\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1644\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langgraph/pregel/retry.py:120\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, task\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2543\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2539\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2540\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2541\u001b[0m )\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2543\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Code/class/research/marco/mhqc/venv/lib/python3.12/site-packages/langgraph/utils.py:117\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m, in \u001b[0;36mexecute_step\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      5\u001b[0m     task_formatted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mFor the following plan:\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mplan_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mYou are tasked with executing step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     agent_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent_executor\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m      8\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, task_formatted)]}\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m: (task, \u001b[43magent_response\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m),\n\u001b[1;32m     12\u001b[0m     }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\"input\": create_objective(\"We have observed an increase in service latency above 2 seconds for more than 20% of user requests, violating service level agreements.\")}\n",
    "async for event in app.astream(inputs, config=config):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
