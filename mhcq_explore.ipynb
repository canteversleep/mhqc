{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99760a29-8e13-47d4-b286-dcc514a01137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict, Union, Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import functools\n",
    "\n",
    "### Agents\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "##\n",
    "\n",
    "### Tools\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "# Utils\n",
    "from pathlib import Path\n",
    "###\n",
    "\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5302c-0846-4532-b516-40e5cf8a6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "load_dotenv() ## ensure that your .env file in the same directory as this notebook has the OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06581cc5-317d-44d8-b202-93eab01da58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool utils\n",
    "\n",
    "WORKING_DIRECTORY = Path('./playground/single_trace/dsph_fL1_orig/')\n",
    "\n",
    "# tavily_tool = TavilySearchResults(max_results=5) # TODO: get TavilyAPIKey\n",
    "python_repl_tool = PythonREPLTool()\n",
    "\n",
    "@tool\n",
    "def scrape_webpages(urls: List[str]) -> str:\n",
    "    \"\"\"Use requests and bs4 to scrape the provided web pages for detailed information.\"\"\"\n",
    "    loader = WebBaseLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'\\n{doc.page_content}\\n'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "@tool # DEP:\n",
    "def get_telemetry(queries: List[str]) -> str: \n",
    "    \"\"\"Use Alessandro's API to request samples of traces and/or metrics (gauges or counters) from prometheus and jaeger.\n",
    "    @TODO: refine type signature for input to be a tuple of counted calls\n",
    "    @TODO: implement the actual functionality\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "## -- File System Interaction Toolkit\n",
    "\n",
    "# This will be run before the anomaly enumeration agents\n",
    "# It makes it so they are more aware of the current state\n",
    "# of the working directory.\n",
    "def prelude(state):\n",
    "    written_files = []\n",
    "    if not WORKING_DIRECTORY.exists():\n",
    "        WORKING_DIRECTORY.mkdir()\n",
    "    try:\n",
    "        written_files = [\n",
    "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
    "        ]\n",
    "    except Exception:\n",
    "        pass\n",
    "    if not written_files:\n",
    "        return {**state, \"current_files\": \"No files written.\"}\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_files\": \"\\nBelow are the files that exist in metrics filesystem DB:\\n\"\n",
    "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
    "    }\n",
    "\n",
    "# TODO: we need to experiment about whether we need to read this at all.\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is not None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d260fbd-449f-4a75-a823-eb46e3c070fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM setup \n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333231bb-03e1-4260-bf88-7c317f58c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8cb54b-5662-4b54-949b-a1dc65cba24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_prompt = (\n",
    "#     \"You are a telemeter tasked with using the provided tool to retrieve\"\n",
    "#     \" all requested metrics and traces by selecting and using the appropriate\"\n",
    "#     \" Jaeger and/or Prometheus API endpoints.\"\n",
    "# )\n",
    "\n",
    "# telemetry_retriever = create_agent(llm, [get_telemetry], gt_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6765cf3-cfeb-41b2-93a4-4ed1d70c5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomdet_prompt = (\n",
    "    \"You are an expert at detecting anomalies in microservice application\"\n",
    "    \" traces and metrics. You will be provided a description of an SLO violation\"\n",
    "    \" as well as telemetrics to mark anomalies. Specifically, you will be provided\"\n",
    "    \" with a working directory's content comprising:\"\n",
    "    \"   1. `main_traces.csv`: which will summarize Jaeger traces for all calls in\"\n",
    "    \"       our workload. This will include the following headers, respectively:\"\n",
    "    \"       traceID,duration-ms,startTime,endTime,rpcErrors,operation,services_involved\"\n",
    "    \"   2. A file for each services Prometheus metrics, exported by cAvisor. The name\"\n",
    "    \"       the file will be the name of the microservice whose system performance\"\n",
    "    \"       metrics we are collecting.\"\n",
    "    \" Use the provided tools and write and execute any safe code necessary to investigate\"\n",
    "    \" potential anomalies. Please mark any anomalies you find by returning their trace IDs\"\n",
    "    \" in the case of traces, or by returning the value ranges you think are anomalous in\"\n",
    "    \" the case of system metrics in a simple list. Elaborate in a simple summary your rationale\"\n",
    "    \" for marking anomalies. If anomalies have not occured, please return a FALSE.\"\n",
    ")\n",
    "\n",
    "substitute_prompt = \"\"\"\n",
    "You are expert at detecting anomalies in Jaeger application traces. You will be given a file in a directory to detect if its trace is anomalous.\n",
    "The trace tree consists of: traceID,duration-ms,startTime,endTime,rpcErrors,operation,services_involved. Be mindful of the fact that the\n",
    "traces provided will be logically cohesive. Anomalies may be in the form of errors or extreme bottlenecks, recursive retries, and otherwise.\n",
    "Please employ all provided tools, code containing any statistical testing or otherwise, read document, do all that is necessary to analyze this trace tree and\n",
    "identify potential anomalies. \n",
    "\n",
    "The following files have been provided: {current_files}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "substitute_prompt_for_baseline = \"\"\"\n",
    "You are expert at detecting anomalies in Jaeger application traces. You will be given a file in a directory to detect if its trace is anomalous.\n",
    "The trace tree for spansconsists of: traceID,spanID, flags, operationName, references, startTime,duration-ms, tags, logs, warnings. Services involved \n",
    "can be deduced by usign the processID and then looking at the processes part of the JSON. Be mindful of the fact that the traces provided will be logically cohesive.\n",
    "Further be mindful that the trace files are extremely large and need to be interacted with programmatically so as to conserve your context window. Anomalies may be inthe form of errors or extreme bottlenecks, recursive retries, and otherwise.\n",
    "Please employ all provided tools, code containing any statistical testing or otherwise, do all that is necessary to analyze this trace tree and\n",
    "identify potential anomalies. \n",
    "\n",
    "The following files have been provided: {current_files}\n",
    "\"\"\"\n",
    "# in the baseline we remove the agents ability to read docs.\n",
    "anomaly_detector = create_agent(llm, [python_repl_tool], substitute_prompt_for_baseline)\n",
    "# anomaly_detector = create_agent(llm, [read_document,python_repl_tool], substitute_prompt_for_baseline)\n",
    "context_aware_anomaly_marker = prelude | anomaly_detector\n",
    "anomaly_detection_agent = functools.partial(agent_node, agent=context_aware_anomaly_marker, name=\"AnomalyDetector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6e90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalousTrace(TypedDict):\n",
    "    trace_id: str\n",
    "    justification: str\n",
    "\n",
    "class AnomalousMetric(TypedDict):\n",
    "    service: str\n",
    "    start_time: int\n",
    "    end_time: int\n",
    "    justification: str\n",
    "    \n",
    "class Anomalies(BaseModel):\n",
    "    anomaly_occured: bool\n",
    "    anomalous_traces: Annotated[Optional[List[AnomalousTrace]], \"A list of anomolous TraceIDs\"]\n",
    "    anomalous_system: Annotated[Optional[List[AnomalousMetric]], \"ranges of anomalous system metrics\"]\n",
    "    commentary: str\n",
    "    \n",
    "# class NonAnomaly(BaseModel):\n",
    "#     anomaly_occured: bool\n",
    "#     pass\n",
    "\n",
    "# AnomalyDetectorOut = Annotated[Union[Anomaly, NonAnomaly], Field(discriminator='anomaly_occured')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee44e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = anomaly_detection_agent({\"messages\": [(\"user\",\"Please check if the traces in the provided directory are anomalous.\")]})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2473e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
