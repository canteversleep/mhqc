{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cdac38-a0b7-4e84-ba48-767a30e00467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, MessagesState\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230726e-00db-4987-a9ae-388b1632e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langGraph MapReduce imports\n",
    "import operator\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, StateGraph, START, MessagesState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b0775-bf62-4073-9773-076e17262cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "load_dotenv() ## ensure that your .env file in the same directory as this notebook has the OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f2102b-b407-4b50-b147-f6c3b861582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df7b08-0844-4261-8a38-3431761df97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.prebuilt import ToolInvocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0fb52-3264-4e53-ab56-a04a31b263b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup tool to anomalous traces with their descriptions and connections to initial prompt\n",
    "@tool\n",
    "def load_anomolous_traces_v1(query: str): # query may not be necessary, or could be the identifier\n",
    "    \"\"\"Inject the anomalous traces and the description of anomaly for hypothesis generation\"\"\"\n",
    "    # In the real implementation, this will not be called at all and will instead\n",
    "    # be handled via mapreduce faculty over all traces with the explorer multimodal LLM.\n",
    "    return [\n",
    "        f\"I have evaluated potential anomalies with {query}. Result: the program appears to be stalling when calling the user identity service, as indicated in the figure provided as part of the query.\"\n",
    "    ]\n",
    "\n",
    "tools = [load_anomolous_traces_v1]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa142212-a752-4641-8840-d262425ffd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [Optionally] if we were using a human feedback mechanism, this is what we would use\n",
    "class RequestAnomalyInejection(BaseModel):\n",
    "    question: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722dad3e-f512-4e55-b06e-32726b56187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now let's bind our tool to the chatbot\n",
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85b135-8c0a-4547-be59-5f5874ffdba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState) -> Literal[\"continue\", \"end\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # [Optionally] If tool call is asking Human, we return that node\n",
    "    # You could also add logic here to let some system know that there's something that requires Human input\n",
    "    # For example, send a slack message, etc\n",
    "    # elif last_message.tool_calls[0][\"name\"] == \"AskHuman\":\n",
    "    #     return \"ask_human\"\n",
    "    # # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "        # return \"tools\"\n",
    "\n",
    "# Optionally, we define a fake node for prompting human\n",
    "# def ask_human(state):\n",
    "#     pass\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627a0f4-0643-48d6-a64e-7ec4c29f44f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build graph\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"explorer\", tool_node)\n",
    "workflow.add_node(\"hypothesizer\", )\n",
    "# [Optionally] workflow.add_node(\"ask_human\", ask_human)\n",
    "\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"explorer\",\n",
    "        # We may ask the human [Optionally]\n",
    "        # \"ask_human\": \"ask_human\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"explorer\", \"hypothesizer\")\n",
    "\n",
    "# optionally After we get back the human response, we go back to the agent\n",
    "# workflow.add_edge(\"ask_human\", \"agent\")\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "# We add a breakpoint BEFORE the `ask_human` node so it never executes\n",
    "# app = workflow.compile(checkpointer=memory, interrupt_before=[\"ask_human\"])\n",
    "\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a901f9b-d049-4cce-8bbe-eb8f146c2609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(\n",
    "    content=\"Use the load_anomalous_traces tool to find anomalies, then tell me what's going on with our program.\"\n",
    ")\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73967302-b255-4d4f-893d-d1adfb91b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
